{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaikwangg/assignment-nlp/blob/main/Assign_QA_WangChanBERTa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6lp69DuaNL0",
        "outputId": "292456cb-57d9-4de0-a643-6693287ed61a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|██████████| 546/546 [00:00<00:00, 279kB/s]\n",
            "Downloading: 100%|██████████| 905k/905k [00:00<00:00, 1.60MB/s]\n",
            "Downloading: 100%|██████████| 282/282 [00:00<00:00, 289kB/s]\n",
            "Downloading: 100%|██████████| 423M/423M [00:29<00:00, 14.6MB/s] \n",
            "Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'logits'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-9-c1abae6bfe30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m   \u001b[0msentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0msentiment_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Negative\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Neutral\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Positive\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'logits'"
          ]
        }
      ],
      "source": [
        "## ตัวอย่างการใข้งาน WangchanBERTa ทำ Sentiment Analysis\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "model_name = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 3)\n",
        "\n",
        "text = \"ไม่อร่อยเลย\"\n",
        "tokens = tokenizer(text, return_tensors='pt')\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model(**tokens)\n",
        "  sentiment = torch.argmax(output.logits, dim=1).item()\n",
        "\n",
        "sentiment_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "print(f\"Sentiment: {sentiment_labels[sentiment]} {sentiment}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rPUYXAATqVR"
      },
      "source": [
        "## TODO\n",
        " WangchanBERTa (https://arxiv.org/abs/2101.09635) is RoBERTa (https://arxiv.org/abs/1907.11692) trained on thai texts. RoBERTa is also supported in Hugging Face (https://huggingface.co/transformers/model_doc/roberta.html).\n",
        "\n",
        "ตัวย่างการใช้ WangchanBERTa: See (https://colab.research.google.com/drive/1Kbk6sBspZLwcnOE61adAQo30xxqOQ9ko?usp=sharing&fbclid=IwAR23b8ZEoP6YxlUx7wWEu7dRCrVcyTFrZb3YSgI-nsxe_t4gy-bh8Rv5R9E#scrollTo=kAcpAdkddVQ8)\n",
        "\n",
        "ให้นักศึกษาทำ QA ในภาษาไทยด้วย WangChanBERTa\n",
        "ตัวอย่าง\n",
        "\n",
        "context : \"ทรูมีแพ็กเกจอินเทอร์เน็ต 10GB ราคา 299 บาทต่อเดือน\"\n",
        "\n",
        "question : \"แพ็กเกจอินเทอร์เน็ตมีกี่ GB?\"\n",
        "\n",
        "ได้คำตอบ: \"10GB\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "import torch\n",
        "\n",
        "model_name = \"cstorm125/wangchanberta-base-att-spm-uncased-finetune-qa\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "thai_qa_pipeline = pipeline(\"question-answering\",\n",
        "                            model=model,\n",
        "                            tokenizer=tokenizer,\n",
        "                            framework=\"pt\")\n",
        "\n",
        "context = \"ทรูมีแพ็กเกจอินเทอร์เน็ต 10GB ราคา 299 บาทต่อเดือน\"\n",
        "question = \"แพ็กเกจอินเทอร์เน็ตมีกี่ GB?\"\n",
        "\n",
        "result = thai_qa_pipeline({\n",
        "    \"context\": context,\n",
        "    \"question\": question\n",
        "})\n",
        "\n",
        "print(\"Context:\", context)\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", result[\"answer\"])\n",
        "print(\"Score:\", result[\"score\"])"
      ],
      "metadata": {
        "id": "zqsIoJcw1AKB",
        "outputId": "23623f83-50cd-4390-8554-0298453940bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: ทรูมีแพ็กเกจอินเทอร์เน็ต 10GB ราคา 299 บาทต่อเดือน\n",
            "Question: แพ็กเกจอินเทอร์เน็ตมีกี่ GB?\n",
            "Answer:  10GB\n",
            "Score: 0.394441157579422\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}